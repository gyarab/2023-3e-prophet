{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is pyhton notebook where you can train your own model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import best_brain as bb\n",
    "from data_manager import LoaderOHLCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_epochs - how many times it will go thorugh all the data\n",
    "- input_file_name - file with training data must be in \"datasets\" folder relative to this notebook\n",
    "- bb.load_data_mode - keep it 2, otherwise model will not work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10 # Epoch: Passes the entire training dataset to the model once\n",
    "input_file_name = 'Full_train_1_minute.csv' #\n",
    "bb.load_data_mode = 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can set name for yor model or, you can set it to \"not_given\" to let the program create you a technical name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name has to end with pth\n",
    "model_name = \"actual_model.pth\" # must be in \"datasets\" folder\n",
    "bb.model_path = bb.create_model_path(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the model to your device (to CPU if you do not have CUDA installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads model to device\n",
    "bb.model.to(bb.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads an prepares dataset\n",
    "DataManager = LoaderOHLCV(bb.look_back,bb.load_data_mode, input_file=input_file_name)\n",
    "X_train, X_test, y_train, y_test = DataManager.get_data_as_tensor()\n",
    "train_dataset, test_dataset = DataManager.to_dataset(X_train, X_test, y_train, y_test)\n",
    "train_loader, test_loader = DataManager.to_dataLoader(train_dataset, test_dataset, bb.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains model\n",
    "bb.train_model(train_loader, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates taining graphs, but those do not give much infomations. It is better to back test the model. Theese graphs show what was the target value and what the model predicted.\n",
    "\n",
    "**Also the train to test data ratio is now hardcoded to 99% train to 1% test ** Since the grpahs do not give any reason able informations. So it is better to train on larger amount of data, to not create gap between training and backtesting or live trading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates grpahs\n",
    "bb.create_train_graph(X_train, y_train)\n",
    "bb.create_test_graph(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
